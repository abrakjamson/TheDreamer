# The Dreamer: An Experiment of Consciousness
There are very few established and verifiable markers of consciousness, and fewer still that today's LLM + chat products do not meet.
*The Dreamer* sets out to meet the remaining aspects of consciousness.
So far, I argue it meets the criteria established by the theories of:
* Functionalism
* Integrated Information Theory
* Global Workspace Theory
* Higher Order Theory

I also argue that *The Dreamer* shows basic levels of:
* Self-awareness
* Subjective experience
* Integration of information
* Adaptability
* Intentionality

## How it works
*The Dreamer* project is a four-agent system:
1. The _Dreamer_ agent takes sensory input of random words and crafts narrative around them.
2. The _Contemplator_ agent thinks about the Dreamer's dreams to devise lessons and potential learnings.
3. The _Rectifier_ determines what learnings are compatible with its existing sense of self. It updates how the system thinks about itself based on what it has learned.
4. The _Commander_ updates the system's goal based on what it has determined about itself.
These systems interact in a loop, continuously. They learn, change, grow, and interact.

The system is designed directly to implement the more popular theories of consciousness, such as:
* Higher order theories suggest that consciousness arises when a mental state is about another mental state, such as being aware of one's own thoughts. *The Dreamer* Contemplator agent is aware of the Dreamer's mental state, while the Rectifier agent is aware of the Contemplator's thoughts. The Commander directs the Rectifier of the current goal.
* Global Workspace Theory likens the mind to a theater, where conscious thoughts are the activities spotlighted on stage at a given moment and broadcast to various unconscious processes. In this project, the Rectifier updates the system's self image, broadcast and used by the Dreamer and Contemplator.
* Basic language models without agent frameworks meet the requirements of Functionalism, whereby the AI convinced a Google researcher that it was conscious by how it acted.

## Prizes
If you can describe why *The Dreamer* AI system is not conscious, you may be elligible for compensation! Send me a message with your argument. 
You can't use a version of the arguments from the next section, and I warn you that I'll use your argument to improve the system. Until I run out of money or interest, let's see if some cash and AI can help humanity define consciousness.

## Responses to arguments
### Only biological brains with neurons may be conscious
This is what I am directlly challenging. What is your argument to support this claim?
### The Dreamer doesn't have true sensory input
I don't think that I could easily add listening to the microphone instead of randomly choosing words. Would you still make this argument?
### The Dreamer only simulates consciousness
This could be. Can you show that you are not a brain-in-a-vat, or that we do not all live in a simulation?
### This code isn't complicated enough
I assure you that the LLMs it runs upon are plenty complicated. How many neurons will equal consciousness?
If you instead argue that the human brain is a network of networks that gives rise to consciousness, pleaes give me a number of agents I need to include in the system.
